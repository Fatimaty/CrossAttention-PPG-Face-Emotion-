# Cross-Attention PPG + Face Emotion Recognition

This repository contains my Master’s project on **multimodal emotion recognition** using:

- Behind-the-ear **PPG signals** (converted to 2D images)
- **Facial images** from a camera
- A **cross-attention–based deep learning model** to fuse both modalities

The main training and evaluation code will be provided as Jupyter notebooks.

## Repository structure (planned)

- `notebooks/` – Jupyter notebooks for preprocessing, training and evaluation  
- `results/` – Example plots (confusion matrix, scalograms, sample predictions)  
- `models/` – Saved model weights (optional)  

> Note: I will upload my main training notebook and additional files later.

## Requirements

The project mainly uses:

- Python 3.8+
- PyTorch
- NumPy, Pandas, SciPy
- scikit-learn
- Matplotlib / Seaborn
- OpenCV (for facial images)

A full `requirements.txt` will be added later.

## Data

The original dataset contains PPG and facial data from human participants.  
Due to privacy/ethics reasons, **raw data is not included** in this repository.

## Author

**Fatimat ul Zahra**  
Department of Artificial Intelligence Convergence, Pukyong National University
